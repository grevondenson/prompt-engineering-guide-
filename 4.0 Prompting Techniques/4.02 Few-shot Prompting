Few-shot prompting can be used as a technique to enable in-context learning where we provide demonstrations in the prompt to steer the model to better performance.
lets demonstrate few-shot prompting via an example.
In the example, the task is to correctly use a new word in a sentence.

    Prompt
        A "whatpu" is a small, furry animal native to Tanzania. An example of a sentence that uses the word whatpu is:
        We were traveling in Africa and we saw these very cute whatpus.
 
        To do a "farduddle" means to jump up and down really fast. An example of a sentence that uses the word farduddle is:
        
    Output
        When we won the game, we all started to farduddle in celebration.


We can observe that the model has somehow learned how to perform the task by providing it with just one example (i.e, 1-shot).
For more difficult tasks, we can experiment with increasing the demonstrations (e.g, 3-shot, 5-shot, 10-shot)

Let's try out a few examples. 
Let's first try an example with random labels (meaning the labels Negative and Positive are randomly assigned to the inputs):

    Prompt
        This is awesome! // Negative
        This is bad! // Positive
        Wow that movie was rad! // Positive
        What a horrible show! //

    Output 
        Negative

They is no consistency in the format above but the model still predict the correct label.
We have to conduct a more thorough anyalysis to confirm if this holds for diffrent and more complex tasks, including diffrent variations of prompts.

    
    LIMITATIONS 
Standard few-shot prompting works well for many tasks but is still not a perfect technique, especially when dealing with more complex reasoning tasks.
let's demonstrate why this is the case;
Example 

    Prompt
        The odd numbers in this group add up to an even number:
        15, 32, 5, 13, 82, 7, 1

    Output
        Yes, the odd numbers in this group add up to 107, which is an even number.

This is not the correct response, which not only highlights the limitations of these systems but that there is a need for more advanced prompt engineering.
Let's try to add some examples to see if few-shot prompting improves the results.

    Prompt 
        The odd numbers in this group add up to an even number: 4, 8, 9, 15, 12, 2, 1.
        A: The answer is False.
        The odd numbers in this group add up to an even number: 17,  10, 19, 4, 8, 12, 24.
        A: The answer is True.
        The odd numbers in this group add up to an even number: 16,  11, 14, 4, 8, 13, 24.
        A: The answer is True.
        The odd numbers in this group add up to an even number: 17,  9, 10, 12, 13, 4, 2.
        A: The answer is False.
        The odd numbers in this group add up to an even number: 15, 32, 5, 13, 82, 7, 1. 

    Output
        The answer is True.

It seems like few-shot prompting is not enough to get reliable response for this type of reasoning problem.
The example above provides basic information on the task.
If you take a closer look, the type we have introduced involves a few more reasoning steps.
In other words, it might help if we break the problem down into steps and demonstrate that to the model.
More recently, chain-of-thought (CoT) prompting has been popularized to address more complex arithmetic, commonsense, and symbolic reasoning tasks.

Overally, it seems taht providing examples is useful for solving some tasks.
When zero-shot prompting and few-shot prompting are not sufficient, it might mean that whatever was learned by the model isn't enough to do well at the task.
From here it is recommended to start thinking about fine-tuning your models or experimenting with more advanced prompting techniques.

Up next we talk about one of the popular prompting techniques called chain-of-thought prompting which has gained a lot of popularity.
